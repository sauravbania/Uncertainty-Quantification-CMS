{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63e8a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Phase 2 features: (100000, 6)\n",
      "Loaded tau features: (100000, 9)\n",
      "Loaded entropy features: (100000, 1)\n",
      "Final Assembled Feature Shape: (100000, 10)\n",
      "   deltaR_mean  deltaR_max  eta_width  phi_width      pt_sum  label      tau1  \\\n",
      "0     0.113489    0.357406   0.036857   0.031937  513.989348    1.0  0.031192   \n",
      "1     0.104943    0.372912   0.025278   0.024072  538.222313    1.0  0.017082   \n",
      "2     0.178022    0.392665   0.022716   0.038971  529.846951    1.0  0.017394   \n",
      "3     0.099346    0.399456   0.048627   0.026427  506.544815    1.0  0.039010   \n",
      "4     0.102658    0.347468   0.038306   0.039376  518.627759    1.0  0.059382   \n",
      "\n",
      "       tau2      tau3   entropy  \n",
      "0  0.024029  0.018583  2.039020  \n",
      "1  0.014936  0.012220  1.947566  \n",
      "2  0.012072  0.009343  1.549192  \n",
      "3  0.031932  0.023717  2.812852  \n",
      "4  0.036577  0.029405  3.208436  \n",
      "Saved full_features.csv to processed/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1. Load Phase 2 features (ΔR, width, pT)\n",
    "# ---------------------------------------------\n",
    "\n",
    "phase2_data = np.load(\"../processed/engineered_features.npz\")\n",
    "\n",
    "# Create Phase 2 DataFrame\n",
    "phase2_df = pd.DataFrame({\n",
    "    \"deltaR_mean\": np.concatenate([phase2_data[\"deltaR_quark_mean\"], phase2_data[\"deltaR_gluon_mean\"]]),\n",
    "    \"deltaR_max\": np.concatenate([phase2_data[\"deltaR_quark_max\"], phase2_data[\"deltaR_gluon_max\"]]),\n",
    "    \"eta_width\": np.concatenate([phase2_data[\"eta_width_quark\"], phase2_data[\"eta_width_gluon\"]]),\n",
    "    \"phi_width\": np.concatenate([phase2_data[\"phi_width_quark\"], phase2_data[\"phi_width_gluon\"]]),\n",
    "    \"pt_sum\": np.concatenate([phase2_data[\"pt_quark\"], phase2_data[\"pt_gluon\"]]),\n",
    "    \"label\": np.concatenate([np.ones_like(phase2_data[\"deltaR_quark_mean\"]), np.zeros_like(phase2_data[\"deltaR_gluon_mean\"])])\n",
    "})\n",
    "\n",
    "print(f\"Loaded Phase 2 features: {phase2_df.shape}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Load tau (τ1, τ2, τ3) features\n",
    "# ---------------------------------------------\n",
    "\n",
    "tau_quark = pd.read_csv(\"../processed/tau_quark.csv\")\n",
    "tau_gluon = pd.read_csv(\"../processed/tau_gluon.csv\")\n",
    "\n",
    "tau_df = pd.concat([tau_quark, tau_gluon], ignore_index=True)\n",
    "\n",
    "print(f\"Loaded tau features: {tau_df.shape}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. Load entropy feature\n",
    "# ---------------------------------------------\n",
    "\n",
    "entropy_quark = pd.read_csv(\"../processed/entropy_quark.csv\", names=[\"entropy\"])\n",
    "entropy_gluon = pd.read_csv(\"../processed/entropy_gluon.csv\", names=[\"entropy\"])\n",
    "\n",
    "# Making sure only correct column\n",
    "entropy_quark = entropy_quark[[\"entropy\"]]\n",
    "entropy_gluon = entropy_gluon[[\"entropy\"]]\n",
    "\n",
    "entropy_df = pd.concat([entropy_quark, entropy_gluon], ignore_index=True)\n",
    "\n",
    "print(f\"Loaded entropy features: {entropy_df.shape}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. Assemble Full Feature Set\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Reset all indices to ensure alignment\n",
    "phase2_df = phase2_df.reset_index(drop=True)\n",
    "tau_df = tau_df.reset_index(drop=True)\n",
    "entropy_df = entropy_df.reset_index(drop=True)\n",
    "\n",
    "# Combine everything\n",
    "full_df = pd.concat([phase2_df, tau_df[[\"tau1\", \"tau2\", \"tau3\"]], entropy_df[[\"entropy\"]]], axis=1)\n",
    "\n",
    "print(f\"Final Assembled Feature Shape: {full_df.shape}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. Display a preview\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(full_df.head())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. Save Assembled Feature Matrix\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Save to CSV\n",
    "full_df.to_csv(\"../processed/full_features.csv\", index=False)\n",
    "print(\"Saved full_features.csv to processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bc5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
